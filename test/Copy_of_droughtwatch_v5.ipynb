{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of droughtwatch-v5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN2z924P7iyzmn+gN0TqlqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e539c864b56471097125b5b42bff9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58d2d2be7dca440497f6a95dc31398ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f22e07dd0df44132bdd02922f0248fb0",
              "IPY_MODEL_47d9a1ead94b486ead029ae754156275"
            ]
          }
        },
        "58d2d2be7dca440497f6a95dc31398ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f22e07dd0df44132bdd02922f0248fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_56f67e93145649ec81a99063023ab1db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.69MB of 1.69MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02637424f776454982be151adec923b9"
          }
        },
        "47d9a1ead94b486ead029ae754156275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe9537488e6b40e0a5486a264bceb433",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c450fd2fa5a41f394ce97c9dd748a92"
          }
        },
        "56f67e93145649ec81a99063023ab1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02637424f776454982be151adec923b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe9537488e6b40e0a5486a264bceb433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c450fd2fa5a41f394ce97c9dd748a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindrabharathi/tf_utils/blob/active_learning_drought_watch/test/Copy_of_droughtwatch_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNriYzKZ6ElS"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization,Concatenate,Lambda,Activation,Input,Dropout\n",
        " \n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        " \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "%matplotlib inline\n",
        "\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "a5BWxG2y_ELW",
        "outputId": "be178115-49c3-466e-dbb0-f75742c6caf2"
      },
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1MB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 28.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 48.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "mIUFi9MA-YtE",
        "outputId": "b7d7210f-6270-4576-aefc-bd843b734d11"
      },
      "source": [
        "run=wandb.init(name='draughtwatch_9', \n",
        "           project='Wandb_Drought_Watch',\n",
        "           notes='Drought Watch dataset with Bands B2-B7, custome ResNet', \n",
        "           tags=['DroughtWatch', 'tf_utils','ResNet'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mravindra\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">draughtwatch_9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ravindra/Wandb_Drought_Watch\" target=\"_blank\">https://wandb.ai/ravindra/Wandb_Drought_Watch</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ravindra/Wandb_Drought_Watch/runs/3pp6jg0w\" target=\"_blank\">https://wandb.ai/ravindra/Wandb_Drought_Watch/runs/3pp6jg0w</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210421_143809-3pp6jg0w</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRtgIa4WLJq9",
        "outputId": "83ece445-6a61-426a-96c2-d0ce49ac8100"
      },
      "source": [
        "!pip install --upgrade git+https://github.com/ravindrabharathi/tf_utils@active_learning_drought_watch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ravindrabharathi/tf_utils@active_learning_drought_watch\n",
            "  Cloning https://github.com/ravindrabharathi/tf_utils (to revision active_learning_drought_watch) to /tmp/pip-req-build-emnfg_cd\n",
            "  Running command git clone -q https://github.com/ravindrabharathi/tf_utils /tmp/pip-req-build-emnfg_cd\n",
            "  Running command git checkout -b active_learning_drought_watch --track origin/active_learning_drought_watch\n",
            "  Switched to a new branch 'active_learning_drought_watch'\n",
            "  Branch 'active_learning_drought_watch' set up to track remote branch 'active_learning_drought_watch' from 'origin'.\n",
            "Building wheels for collected packages: tf-utils\n",
            "  Building wheel for tf-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf-utils: filename=tf_utils-0.4-cp37-none-any.whl size=8986 sha256=65578ee97ec492cddbcf3720c67779a924ab81547dfbf6d2d95943e8c23b0c68\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1klk2fsu/wheels/80/a8/35/f3e2a85eff1b8cb7e5e54cbd69a209356cf2153f9a4ee67904\n",
            "Successfully built tf-utils\n",
            "Installing collected packages: tf-utils\n",
            "Successfully installed tf-utils-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASBLPHIDLjb5"
      },
      "source": [
        "import tf_utils.data as ds \n",
        "import tf_utils.visualize as vz\n",
        "import tf_utils.transform as tfm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WC8V27woTPo",
        "outputId": "e910736f-5d6a-46f4-c03c-5c1ef93de2c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE5wbjZfoQ8n"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro8PbfCut_hk"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMh5pUpCuFB2"
      },
      "source": [
        "dirlist = lambda di: [os.path.join(di, file) for file in os.listdir(di) if 'part-' in file]\n",
        "training_files = dirlist('/gdrive/MyDrive/wandb-dw/data/droughtwatch_data/train/')\n",
        "val_files = dirlist('/gdrive/MyDrive/wandb-dw/data/droughtwatch_data/val/')\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj4EpDYt6iIe",
        "outputId": "daf1824c-23e3-4ddb-8611-56a4ec05f2dc"
      },
      "source": [
        "train_ds=ds.get_train_ds(training_files,batch_size=ds.batch_size,shuffle=True,distort=True,distort_fn=tfm.aug1)\n",
        "#unlabelled_ds=ds.get_unlabelled_ds()\n",
        "test_ds=ds.get_test_ds(val_files)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distorting...\n",
            "Finished 'get_tf_dataset_2' in 3.7878 secs\n",
            "Finished 'get_tf_dataset_in_batches' in 3.7888 secs\n",
            "Finished 'get_train_ds' in 3.7891 secs\n",
            "Finished 'get_tf_dataset_2' in 0.0804 secs\n",
            "Finished 'get_tf_dataset_in_batches' in 0.0808 secs\n",
            "Finished 'get_test_ds' in 0.0811 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3y3TzDXOCKci",
        "outputId": "f48c1634-89e1-426d-be87-1ca4ceaf980b"
      },
      "source": [
        "'''\n",
        "for idx, row in enumerate(train_ds):\n",
        "    print (row)\n",
        "    if idx > 1:\n",
        "        break\n",
        "\n",
        "'''        "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor idx, row in enumerate(train_ds):\\n    print (row)\\n    if idx > 1:\\n        break\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m26XDkJi1YyS"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D,  Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ludku7wVG4yD",
        "outputId": "d9e3e3a6-2452-4d8e-953b-c9cc0265d222"
      },
      "source": [
        "'''\n",
        "def conv(inp,f=32,k=3):\n",
        "  conv_layer=Conv2D(f,k,use_bias=False,padding='same')(inp)\n",
        "  conv_layer=BatchNormalization()(conv_layer)\n",
        "  conv_layer=Activation('relu')(conv_layer)\n",
        "  return conv_layer\n",
        "'''  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef conv(inp,f=32,k=3):\\n  conv_layer=Conv2D(f,k,use_bias=False,padding='same')(inp)\\n  conv_layer=BatchNormalization()(conv_layer)\\n  conv_layer=Activation('relu')(conv_layer)\\n  return conv_layer\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw9GlcR4wqvJ"
      },
      "source": [
        "import math\n",
        "WEIGHT_DECAY=1.25e-4\n",
        "reg=tf.keras.regularizers.l2(WEIGHT_DECAY)\n",
        "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
        "  fan = np.prod(shape[:-1])\n",
        "  bound = 1 / math.sqrt(fan)\n",
        "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)\n",
        "\n",
        "def conv(inp,f=32,k=3):\n",
        "  conv_layer=Conv2D(f,k,use_bias=False,padding='same',kernel_initializer=init_pytorch, kernel_regularizer=reg)(inp)\n",
        "  conv_layer=BatchNormalization(momentum=0.9, epsilon=1e-5)(conv_layer)\n",
        "  conv_layer=Activation('relu')(conv_layer)\n",
        "  return conv_layer\n",
        "def resBlk(inp,f=32,k=3,residual=True) :\n",
        "  res1=conv(inp,f,k)\n",
        "  res1=MaxPooling2D(pool_size=(2,2))(res1)\n",
        "  if residual:\n",
        "    res2=conv(res1,f,k)\n",
        "    res3=conv(res2,f,k)\n",
        "    return res1+res3\n",
        "  else:\n",
        "    return res1  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeeP8Mg9x6cB"
      },
      "source": [
        "def build_model():\n",
        "  f=64\n",
        "  inp=Input(shape=(65,65,6))\n",
        "  layer1=conv(inp,f,3)\n",
        "  res1=resBlk(layer1,f*3,3)\n",
        "  \n",
        "  res2=resBlk(res1,f*6,3,False)\n",
        "  \n",
        "  res3=resBlk(res2,f*12,3)\n",
        "\n",
        "  #res4=resBlk(res3,f*8,3,False)\n",
        "\n",
        "  #res5=resBlk(res4,f*8,3)\n",
        "  \n",
        "  \n",
        "  layer2=tf.keras.layers.GlobalMaxPooling2D()(res3)\n",
        "  layer3=tf.keras.layers.Dense(4, kernel_initializer=init_pytorch, use_bias=False,kernel_regularizer=reg)(layer2)\n",
        "  layer4=Lambda(lambda x: x*0.125)(layer3)\n",
        "  out=Activation('softmax')(layer4)\n",
        "  model=tf.keras.models.Model(inputs=[inp],outputs=[out])\n",
        "  model.summary()\n",
        "  return model "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t3HmqE-464Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73d36fb-815b-4894-d45f-56fe8bb3b375"
      },
      "source": [
        "model=build_model()\n",
        "opt=SGD(lr=0.0001,momentum=0.9,nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,metrics=['accuracy']\n",
        "              )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 65, 65, 6)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 65, 65, 64)   3456        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 65, 65, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 65, 65, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 65, 65, 192)  110592      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 65, 65, 192)  768         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 65, 65, 192)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 192)  0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 192)  331776      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 192)  768         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 192)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 192)  331776      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 192)  768         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 192)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 32, 32, 192)  0           max_pooling2d_3[0][0]            \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 384)  663552      tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 384)  1536        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 384)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 384)  0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 768)  2654208     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 768)  3072        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 768)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 768)    0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 768)    5308416     max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 768)    3072        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 768)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 768)    5308416     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 768)    3072        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 768)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 8, 8, 768)    0           max_pooling2d_5[0][0]            \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 768)          0           tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            3072        global_max_pooling2d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 4)            0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4)            0           lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 14,728,576\n",
            "Trainable params: 14,721,920\n",
            "Non-trainable params: 6,656\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTxUQ6h0mwQB"
      },
      "source": [
        "class Log2wandb_Callback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    wandb.log({\n",
        "        \"Epoch\": epoch,\n",
        "        \"Train Loss\": logs[\"loss\"],\n",
        "        \"Train Acc\": logs[\"accuracy\"],\n",
        "        \"Val Loss\": logs[\"val_loss\"],\n",
        "        \"val_acc\": logs[\"val_accuracy\"],\n",
        "        \"LR\":model.optimizer.lr.numpy()\n",
        "        \n",
        "        })\n",
        "        "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edgH88s94pAZ"
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def lr_schedule():\n",
        "    \n",
        "    def schedule(epoch):\n",
        "      \n",
        "      lr=np.interp([epoch],[0, EPOCHS//5,EPOCHS//2,EPOCHS], [0.0001, 0.1, 0.006,0.001])[0]\n",
        "      print('epoch ', epoch+1, ': setting learning rate to ',lr)\n",
        "      return lr\n",
        "    \n",
        "    return LearningRateScheduler(schedule)\n",
        "\n",
        "lr_sched = lr_schedule()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADezwutCtnWu"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_cpt=ModelCheckpoint(filepath='/gdrive/MyDrive/wandb-dw/best_model2.h5', \n",
        "                          verbose=1, save_best_only=True,monitor='val_accuracy',mode='auto')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI4tvwOmAxmx",
        "outputId": "9d1ba092-f57d-4827-eacb-9c0f1391c29b"
      },
      "source": [
        "import numpy as np\n",
        "batch_size=128\n",
        "EPOCHS=20\n",
        "callback_list=[Log2wandb_Callback(),lr_sched,model_cpt]\n",
        "model.fit(train_ds,epochs=EPOCHS, steps_per_epoch=np.ceil(86317/batch_size), \n",
        "          validation_data=test_ds, validation_steps=np.ceil(10778/batch_size),\n",
        "          callbacks=callback_list,\n",
        "          verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "epoch  1 : setting learning rate to  0.0001\n",
            "  6/675 [..............................] - ETA: 1:14 - loss: 1.5991 - accuracy: 0.0940WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0417s vs `on_train_batch_end` time: 0.0582s). Check your callbacks.\n",
            "675/675 [==============================] - 461s 647ms/step - loss: 1.2179 - accuracy: 0.5767 - val_loss: 1.3341 - val_accuracy: 0.5953\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.59531, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 2/20\n",
            "epoch  2 : setting learning rate to  0.025075\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 1.0850 - accuracy: 0.6265 - val_loss: 1.1056 - val_accuracy: 0.6441\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.59531 to 0.64412, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 3/20\n",
            "epoch  3 : setting learning rate to  0.050050000000000004\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.9779 - accuracy: 0.6698 - val_loss: 1.1051 - val_accuracy: 0.5861\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.64412\n",
            "Epoch 4/20\n",
            "epoch  4 : setting learning rate to  0.07502500000000001\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.9199 - accuracy: 0.6949 - val_loss: 0.9108 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.64412 to 0.69844, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 5/20\n",
            "epoch  5 : setting learning rate to  0.1\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.8978 - accuracy: 0.7026 - val_loss: 0.9023 - val_accuracy: 0.6994\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.69844 to 0.69936, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 6/20\n",
            "epoch  6 : setting learning rate to  0.08433333333333334\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.8263 - accuracy: 0.7296 - val_loss: 0.9090 - val_accuracy: 0.6986\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.69936\n",
            "Epoch 7/20\n",
            "epoch  7 : setting learning rate to  0.06866666666666668\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.7789 - accuracy: 0.7443 - val_loss: 0.8917 - val_accuracy: 0.7084\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.69936 to 0.70836, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 8/20\n",
            "epoch  8 : setting learning rate to  0.053000000000000005\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.7446 - accuracy: 0.7547 - val_loss: 0.9011 - val_accuracy: 0.7199\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.70836 to 0.71985, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 9/20\n",
            "epoch  9 : setting learning rate to  0.03733333333333334\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.7166 - accuracy: 0.7659 - val_loss: 0.7686 - val_accuracy: 0.7473\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.71985 to 0.74733, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 10/20\n",
            "epoch  10 : setting learning rate to  0.02166666666666668\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.6751 - accuracy: 0.7780 - val_loss: 0.7297 - val_accuracy: 0.7535\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.74733 to 0.75349, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 11/20\n",
            "epoch  11 : setting learning rate to  0.006\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.6366 - accuracy: 0.7915 - val_loss: 0.6892 - val_accuracy: 0.7700\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.75349 to 0.77004, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 12/20\n",
            "epoch  12 : setting learning rate to  0.0055\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.6235 - accuracy: 0.7953 - val_loss: 0.6885 - val_accuracy: 0.7711\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.77004 to 0.77114, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 13/20\n",
            "epoch  13 : setting learning rate to  0.005\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.6116 - accuracy: 0.8011 - val_loss: 0.6822 - val_accuracy: 0.7719\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.77114 to 0.77188, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 14/20\n",
            "epoch  14 : setting learning rate to  0.0045000000000000005\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.6099 - accuracy: 0.7997 - val_loss: 0.6749 - val_accuracy: 0.7753\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.77188 to 0.77528, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 15/20\n",
            "epoch  15 : setting learning rate to  0.004\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.6013 - accuracy: 0.8049 - val_loss: 0.6782 - val_accuracy: 0.7676\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.77528\n",
            "Epoch 16/20\n",
            "epoch  16 : setting learning rate to  0.0035\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5935 - accuracy: 0.8068 - val_loss: 0.6713 - val_accuracy: 0.7754\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.77528 to 0.77537, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 17/20\n",
            "epoch  17 : setting learning rate to  0.003\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5861 - accuracy: 0.8101 - val_loss: 0.6668 - val_accuracy: 0.7747\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.77537\n",
            "Epoch 18/20\n",
            "epoch  18 : setting learning rate to  0.0025\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5768 - accuracy: 0.8116 - val_loss: 0.6683 - val_accuracy: 0.7758\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.77537 to 0.77583, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 19/20\n",
            "epoch  19 : setting learning rate to  0.002\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5713 - accuracy: 0.8158 - val_loss: 0.6644 - val_accuracy: 0.7749\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.77583\n",
            "Epoch 20/20\n",
            "epoch  20 : setting learning rate to  0.0014999999999999996\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5714 - accuracy: 0.8145 - val_loss: 0.6604 - val_accuracy: 0.7755\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.77583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29d06d1d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcOCYnOkbLL"
      },
      "source": [
        "def lr_schedule():\n",
        "    \n",
        "    def schedule(epoch):\n",
        "      \n",
        "      lr=np.interp([epoch],[20,25,EPOCHS], [0.001,0.005, 0.0001])[0]\n",
        "      print('epoch ', epoch+1, ': setting learning rate to ',lr)\n",
        "      return lr\n",
        "    \n",
        "    return LearningRateScheduler(schedule)\n",
        "\n",
        "lr_sched = lr_schedule()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0__Iol7HANYZ"
      },
      "source": [
        "cust = {'init_pytorch': init_pytorch}\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlvSbBuS_oQa"
      },
      "source": [
        "model=load_model('/gdrive/MyDrive/wandb-dw/best_model2.h5',cust)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArHlpbUK_oQh"
      },
      "source": [
        "opt=SGD(lr=0.001,momentum=0.9,nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,metrics=['accuracy']\n",
        "              )"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjBcmd7GruFg"
      },
      "source": [
        "#train_ds=ds.get_train_ds(training_files,batch_size=ds.batch_size,shuffle=True,distort=True,distort_fn=tfm.aug2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5UwDgvvUIBM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c665ae-01c4-4962-c678-c6abe8309260"
      },
      "source": [
        "import numpy as np\n",
        "batch_size=128\n",
        "EPOCHS=40\n",
        "callback_list=[Log2wandb_Callback(),lr_sched,model_cpt]\n",
        "model.fit(train_ds,epochs=EPOCHS, steps_per_epoch=np.ceil(86317/batch_size), initial_epoch=20,\n",
        "          validation_data=test_ds, validation_steps=np.ceil(10778/batch_size),\n",
        "          callbacks=callback_list,\n",
        "          verbose=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/40\n",
            "epoch  21 : setting learning rate to  0.001\n",
            "  6/675 [..............................] - ETA: 1:16 - loss: 0.5999 - accuracy: 0.8047WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0428s vs `on_train_batch_end` time: 0.0712s). Check your callbacks.\n",
            "675/675 [==============================] - 80s 117ms/step - loss: 0.5768 - accuracy: 0.8127 - val_loss: 0.6630 - val_accuracy: 0.7745\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.77583\n",
            "Epoch 22/40\n",
            "epoch  22 : setting learning rate to  0.0018\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5694 - accuracy: 0.8154 - val_loss: 0.6641 - val_accuracy: 0.7785\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.77583 to 0.77849, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 23/40\n",
            "epoch  23 : setting learning rate to  0.0026\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5693 - accuracy: 0.8144 - val_loss: 0.6639 - val_accuracy: 0.7753\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.77849\n",
            "Epoch 24/40\n",
            "epoch  24 : setting learning rate to  0.0034000000000000002\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5688 - accuracy: 0.8136 - val_loss: 0.6706 - val_accuracy: 0.7743\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.77849\n",
            "Epoch 25/40\n",
            "epoch  25 : setting learning rate to  0.004200000000000001\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5685 - accuracy: 0.8132 - val_loss: 0.6752 - val_accuracy: 0.7743\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.77849\n",
            "Epoch 26/40\n",
            "epoch  26 : setting learning rate to  0.005\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5665 - accuracy: 0.8141 - val_loss: 0.6758 - val_accuracy: 0.7736\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.77849\n",
            "Epoch 27/40\n",
            "epoch  27 : setting learning rate to  0.004673333333333333\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5619 - accuracy: 0.8143 - val_loss: 0.6663 - val_accuracy: 0.7738\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.77849\n",
            "Epoch 28/40\n",
            "epoch  28 : setting learning rate to  0.004346666666666667\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5518 - accuracy: 0.8208 - val_loss: 0.6696 - val_accuracy: 0.7740\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.77849\n",
            "Epoch 29/40\n",
            "epoch  29 : setting learning rate to  0.00402\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5448 - accuracy: 0.8228 - val_loss: 0.6722 - val_accuracy: 0.7678\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.77849\n",
            "Epoch 30/40\n",
            "epoch  30 : setting learning rate to  0.003693333333333333\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5406 - accuracy: 0.8252 - val_loss: 0.6623 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.77849 to 0.77877, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 31/40\n",
            "epoch  31 : setting learning rate to  0.0033666666666666667\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5342 - accuracy: 0.8271 - val_loss: 0.6702 - val_accuracy: 0.7737\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.77877\n",
            "Epoch 32/40\n",
            "epoch  32 : setting learning rate to  0.00304\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5291 - accuracy: 0.8278 - val_loss: 0.6679 - val_accuracy: 0.7727\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.77877\n",
            "Epoch 33/40\n",
            "epoch  33 : setting learning rate to  0.0027133333333333332\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5209 - accuracy: 0.8311 - val_loss: 0.6673 - val_accuracy: 0.7741\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.77877\n",
            "Epoch 34/40\n",
            "epoch  34 : setting learning rate to  0.0023866666666666667\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5201 - accuracy: 0.8310 - val_loss: 0.6614 - val_accuracy: 0.7775\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.77877\n",
            "Epoch 35/40\n",
            "epoch  35 : setting learning rate to  0.00206\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5102 - accuracy: 0.8332 - val_loss: 0.6648 - val_accuracy: 0.7754\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.77877\n",
            "Epoch 36/40\n",
            "epoch  36 : setting learning rate to  0.0017333333333333333\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.5046 - accuracy: 0.8365 - val_loss: 0.6625 - val_accuracy: 0.7783\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.77877\n",
            "Epoch 37/40\n",
            "epoch  37 : setting learning rate to  0.0014066666666666667\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.4951 - accuracy: 0.8423 - val_loss: 0.6563 - val_accuracy: 0.7767\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.77877\n",
            "Epoch 38/40\n",
            "epoch  38 : setting learning rate to  0.0010800000000000002\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.4894 - accuracy: 0.8457 - val_loss: 0.6563 - val_accuracy: 0.7816\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.77877 to 0.78162, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n",
            "Epoch 39/40\n",
            "epoch  39 : setting learning rate to  0.0007533333333333333\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.4877 - accuracy: 0.8440 - val_loss: 0.6562 - val_accuracy: 0.7795\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.78162\n",
            "Epoch 40/40\n",
            "epoch  40 : setting learning rate to  0.00042666666666666634\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.4774 - accuracy: 0.8500 - val_loss: 0.6549 - val_accuracy: 0.7817\n",
            "\n",
            "Epoch 00040: val_accuracy improved from 0.78162 to 0.78171, saving model to /gdrive/MyDrive/wandb-dw/best_model2.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f296c5445d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoZeiutzGlkl",
        "outputId": "042a0edd-ea6c-4ff6-c625-47b234d2006c"
      },
      "source": [
        "train_ds=ds.get_train_ds(training_files,batch_size=ds.batch_size,shuffle=True,distort=True,distort_fn=tfm.aug1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distorting...\n",
            "Finished 'get_tf_dataset_2' in 0.2070 secs\n",
            "Finished 'get_tf_dataset_in_batches' in 0.2073 secs\n",
            "Finished 'get_train_ds' in 0.2077 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPNqt6Gk7oD1"
      },
      "source": [
        "model=load_model('/gdrive/MyDrive/wandb-dw/best_model2.h5',cust)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0UOlh1h8Ozt"
      },
      "source": [
        "opt=SGD(lr=0.00042,momentum=0.9,nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,metrics=['accuracy']\n",
        "              )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecGf4bOl79j3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479c5e8a-d8b5-4eec-9f00-1bb6a63f2eb2"
      },
      "source": [
        "EPOCHS=41\n",
        "callback_list=[Log2wandb_Callback(),model_cpt]\n",
        "model.fit(train_ds,epochs=EPOCHS, steps_per_epoch=np.ceil(86317/batch_size), initial_epoch=40,\n",
        "          validation_data=test_ds, validation_steps=np.ceil(10778/batch_size),\n",
        "          callbacks=callback_list,\n",
        "          verbose=1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/41\n",
            "  6/675 [..............................] - ETA: 1:15 - loss: 0.4683 - accuracy: 0.8555WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0415s vs `on_train_batch_end` time: 0.0713s). Check your callbacks.\n",
            "675/675 [==============================] - 78s 116ms/step - loss: 0.4693 - accuracy: 0.8524 - val_loss: 0.6566 - val_accuracy: 0.7803\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.78171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29264cfe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erylHhUun9v9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667,
          "referenced_widgets": [
            "1e539c864b56471097125b5b42bff9ec",
            "58d2d2be7dca440497f6a95dc31398ae",
            "f22e07dd0df44132bdd02922f0248fb0",
            "47d9a1ead94b486ead029ae754156275",
            "56f67e93145649ec81a99063023ab1db",
            "02637424f776454982be151adec923b9",
            "fe9537488e6b40e0a5486a264bceb433",
            "4c450fd2fa5a41f394ce97c9dd748a92"
          ]
        },
        "outputId": "48e455c2-2515-4903-877a-904c64e9a3c7"
      },
      "source": [
        "run.finish()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 149<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e539c864b56471097125b5b42bff9ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 1.66MB of 1.66MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210421_143809-3pp6jg0w/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210421_143809-3pp6jg0w/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Epoch</td><td>40</td></tr><tr><td>Train Loss</td><td>0.46932</td></tr><tr><td>Train Acc</td><td>0.85243</td></tr><tr><td>Val Loss</td><td>0.65664</td></tr><tr><td>val_acc</td><td>0.78033</td></tr><tr><td>LR</td><td>0.00042</td></tr><tr><td>_runtime</td><td>5345</td></tr><tr><td>_timestamp</td><td>1619021234</td></tr><tr><td>_step</td><td>48</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Acc</td><td>▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>Val Loss</td><td>█▆▆▄▄▃▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▁▅▅▅▆▇▇███▇███████████████████████████</td></tr><tr><td>LR</td><td>▁▃▅▆█▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 47 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">draughtwatch_9</strong>: <a href=\"https://wandb.ai/ravindra/Wandb_Drought_Watch/runs/3pp6jg0w\" target=\"_blank\">https://wandb.ai/ravindra/Wandb_Drought_Watch/runs/3pp6jg0w</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}