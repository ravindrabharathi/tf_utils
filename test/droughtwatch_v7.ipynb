{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "droughtwatch-v7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO4AwL6TQa73RsR/Vhq3h5d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ece48fd90394113b804b0907f6ad64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c10d50541c764f13bb1198ece143454a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43fccec0bc24409ca6030de32754c89d",
              "IPY_MODEL_b2c98bc8761445d0b699b4449d24fc1a"
            ]
          }
        },
        "c10d50541c764f13bb1198ece143454a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43fccec0bc24409ca6030de32754c89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_433d0f9aba0a472696b9d790e8a35e59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.70MB of 0.70MB uploaded (0.04MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4756c0d7dc146b19c693170c70dce42"
          }
        },
        "b2c98bc8761445d0b699b4449d24fc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55c50e2922404090a009ad6e6827bb9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9847692c052c4b889f51cf9b3a2ca768"
          }
        },
        "433d0f9aba0a472696b9d790e8a35e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4756c0d7dc146b19c693170c70dce42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55c50e2922404090a009ad6e6827bb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9847692c052c4b889f51cf9b3a2ca768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindrabharathi/tf_utils/blob/active_learning_drought_watch/test/droughtwatch_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNriYzKZ6ElS"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization,Concatenate,Lambda,Activation,Input,Dropout\n",
        " \n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        " \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "%matplotlib inline\n",
        "\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "a5BWxG2y_ELW",
        "outputId": "0aa9caa6-4352-45e4-ecd1-02986392bb97"
      },
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1MB 14.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 51.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 59.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "mIUFi9MA-YtE",
        "outputId": "72bf9c71-f47e-486d-e32e-d035c0717f6c"
      },
      "source": [
        "run=wandb.init(name='draughtwatch_12', \n",
        "           project='Wandb_Drought_Watch',\n",
        "           notes='Drought Watch dataset with Bands B2-B7, custom ResNet', \n",
        "           tags=['DroughtWatch', 'tf_utils','ResNet'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mravindra\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">draughtwatch_12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ravindra/Wandb_Drought_Watch\" target=\"_blank\">https://wandb.ai/ravindra/Wandb_Drought_Watch</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ravindra/Wandb_Drought_Watch/runs/10pdt7my\" target=\"_blank\">https://wandb.ai/ravindra/Wandb_Drought_Watch/runs/10pdt7my</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210421_151151-10pdt7my</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRtgIa4WLJq9",
        "outputId": "fa26939b-906c-481c-bee3-2662aa840d30"
      },
      "source": [
        "!pip install --upgrade git+https://github.com/ravindrabharathi/tf_utils@active_learning_drought_watch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ravindrabharathi/tf_utils@active_learning_drought_watch\n",
            "  Cloning https://github.com/ravindrabharathi/tf_utils (to revision active_learning_drought_watch) to /tmp/pip-req-build-4lv_11g3\n",
            "  Running command git clone -q https://github.com/ravindrabharathi/tf_utils /tmp/pip-req-build-4lv_11g3\n",
            "  Running command git checkout -b active_learning_drought_watch --track origin/active_learning_drought_watch\n",
            "  Switched to a new branch 'active_learning_drought_watch'\n",
            "  Branch 'active_learning_drought_watch' set up to track remote branch 'active_learning_drought_watch' from 'origin'.\n",
            "Building wheels for collected packages: tf-utils\n",
            "  Building wheel for tf-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf-utils: filename=tf_utils-0.4-cp37-none-any.whl size=8996 sha256=650dda2d57b91b12b77a2b07590cea816ccf03cbedb401345d6db673ca378732\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ejopt_55/wheels/80/a8/35/f3e2a85eff1b8cb7e5e54cbd69a209356cf2153f9a4ee67904\n",
            "Successfully built tf-utils\n",
            "Installing collected packages: tf-utils\n",
            "Successfully installed tf-utils-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASBLPHIDLjb5"
      },
      "source": [
        "import tf_utils.data as ds \n",
        "import tf_utils.visualize as vz\n",
        "import tf_utils.transform as tfm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WC8V27woTPo",
        "outputId": "4273763c-fb82-4961-db2c-08167cccf324"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE5wbjZfoQ8n"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro8PbfCut_hk"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMh5pUpCuFB2"
      },
      "source": [
        "dirlist = lambda di: [os.path.join(di, file) for file in os.listdir(di) if 'part-' in file]\n",
        "training_files = dirlist('/gdrive/MyDrive/wandb-dw/data/droughtwatch_data/train/')\n",
        "val_files = dirlist('/gdrive/MyDrive/wandb-dw/data/droughtwatch_data/val/')\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj4EpDYt6iIe",
        "outputId": "b169d785-f49d-4ccb-8354-584325fd8852"
      },
      "source": [
        "train_ds=ds.get_train_ds(training_files,batch_size=ds.batch_size,shuffle=True,distort=True,distort_fn=tfm.aug1)\n",
        "#unlabelled_ds=ds.get_unlabelled_ds()\n",
        "test_ds=ds.get_test_ds(val_files)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distorting...\n",
            "Finished 'get_tf_dataset_2' in 3.7929 secs\n",
            "Finished 'get_tf_dataset_in_batches' in 3.7933 secs\n",
            "Finished 'get_train_ds' in 3.7935 secs\n",
            "Finished 'get_tf_dataset_2' in 0.0763 secs\n",
            "Finished 'get_tf_dataset_in_batches' in 0.0766 secs\n",
            "Finished 'get_test_ds' in 0.0774 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3y3TzDXOCKci",
        "outputId": "7bdd7bd1-52fe-4718-ce56-0adbcb8c4b37"
      },
      "source": [
        "'''\n",
        "for idx, row in enumerate(train_ds):\n",
        "    print (row)\n",
        "    if idx > 1:\n",
        "        break\n",
        "\n",
        "'''        "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor idx, row in enumerate(train_ds):\\n    print (row)\\n    if idx > 1:\\n        break\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m26XDkJi1YyS"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D,  Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ludku7wVG4yD",
        "outputId": "786cb402-f7fa-4eb8-bb46-29bc5b9ec2f4"
      },
      "source": [
        "'''\n",
        "def conv(inp,f=32,k=3):\n",
        "  conv_layer=Conv2D(f,k,use_bias=False,padding='same')(inp)\n",
        "  conv_layer=BatchNormalization()(conv_layer)\n",
        "  conv_layer=Activation('relu')(conv_layer)\n",
        "  return conv_layer\n",
        "'''  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef conv(inp,f=32,k=3):\\n  conv_layer=Conv2D(f,k,use_bias=False,padding='same')(inp)\\n  conv_layer=BatchNormalization()(conv_layer)\\n  conv_layer=Activation('relu')(conv_layer)\\n  return conv_layer\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw9GlcR4wqvJ"
      },
      "source": [
        "import math\n",
        "WEIGHT_DECAY=1.25e-4\n",
        "reg=tf.keras.regularizers.l2(WEIGHT_DECAY)\n",
        "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
        "  fan = np.prod(shape[:-1])\n",
        "  bound = 1 / math.sqrt(fan)\n",
        "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)\n",
        "\n",
        "def conv(inp,f=32,k=3):\n",
        "  conv_layer=Conv2D(f,k,use_bias=False,padding='same',kernel_initializer=init_pytorch, kernel_regularizer=reg)(inp)\n",
        "  conv_layer=BatchNormalization(momentum=0.9, epsilon=1e-5)(conv_layer)\n",
        "  conv_layer=Activation('relu')(conv_layer)\n",
        "  return conv_layer\n",
        "def resBlk(inp,f=32,k=3,residual=True) :\n",
        "  res1=conv(inp,f,k)\n",
        "  res1=MaxPooling2D(pool_size=(2,2))(res1)\n",
        "  if residual:\n",
        "    res2=conv(res1,f,k)\n",
        "    res3=conv(res2,f,k)\n",
        "    return res1+res3\n",
        "  else:\n",
        "    return res1  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeeP8Mg9x6cB"
      },
      "source": [
        "def build_model():\n",
        "  f=64\n",
        "  inp=Input(shape=(65,65,6))\n",
        "  layer1=conv(inp,f,3)\n",
        "  res1=resBlk(layer1,f*2,3)\n",
        "  \n",
        "  res2=resBlk(res1,f*4,3,False)\n",
        "  \n",
        "  res3=resBlk(res2,f*8,3)\n",
        "\n",
        "  #res4=resBlk(res3,f*8,3,False)\n",
        "\n",
        "  #res5=resBlk(res4,f*8,3)\n",
        "  \n",
        "  \n",
        "  layer2=tf.keras.layers.GlobalMaxPooling2D()(res3)\n",
        "  layer3=tf.keras.layers.Dense(4, kernel_initializer=init_pytorch, use_bias=False,kernel_regularizer=reg)(layer2)\n",
        "  layer4=Lambda(lambda x: x*0.125)(layer3)\n",
        "  out=Activation('softmax')(layer4)\n",
        "  model=tf.keras.models.Model(inputs=[inp],outputs=[out])\n",
        "  model.summary()\n",
        "  return model "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t3HmqE-464Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0babead8-1e3f-495e-b6e8-5fa08a48a159"
      },
      "source": [
        "model=build_model()\n",
        "opt=SGD(lr=0.0001,momentum=0.9,nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,metrics=['accuracy']\n",
        "              )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 65, 65, 6)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 65, 65, 64)   3456        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 65, 65, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 65, 65, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 65, 65, 128)  73728       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 65, 65, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 65, 65, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 128)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 128)  147456      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 128)  147456      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 32, 32, 128)  0           max_pooling2d[0][0]              \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 256)  294912      tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 512)  1179648     max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 512)  2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 512)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 512)    0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 8, 8, 512)    2359296     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 8, 512)    2048        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 512)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 8, 8, 512)    2359296     activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 8, 8, 512)    2048        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 512)    0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 8, 8, 512)    0           max_pooling2d_2[0][0]            \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 512)          0           tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            2048        global_max_pooling2d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 4)            0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 4)            0           lambda[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 6,576,256\n",
            "Trainable params: 6,571,776\n",
            "Non-trainable params: 4,480\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTxUQ6h0mwQB"
      },
      "source": [
        "class Log2wandb_Callback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    wandb.log({\n",
        "        \"Epoch\": epoch,\n",
        "        \"Train Loss\": logs[\"loss\"],\n",
        "        \"Train Acc\": logs[\"accuracy\"],\n",
        "        \"Val Loss\": logs[\"val_loss\"],\n",
        "        \"val_acc\": logs[\"val_accuracy\"],\n",
        "        \"LR\":model.optimizer.lr.numpy()\n",
        "        \n",
        "        })\n",
        "        "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edgH88s94pAZ"
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def lr_schedule():\n",
        "    \n",
        "    def schedule(epoch):\n",
        "      \n",
        "      lr=np.interp([epoch],[0, EPOCHS//5,EPOCHS//2,EPOCHS], [0.0001, 0.1, 0.006,0.001])[0]\n",
        "      print('epoch ', epoch+1, ': setting learning rate to ',lr)\n",
        "      return lr\n",
        "    \n",
        "    return LearningRateScheduler(schedule)\n",
        "\n",
        "lr_sched = lr_schedule()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADezwutCtnWu"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_cpt=ModelCheckpoint(filepath='/gdrive/MyDrive/wandb-dw/best_model12.h5', \n",
        "                          verbose=1, save_best_only=True,monitor='val_accuracy',mode='auto')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI4tvwOmAxmx",
        "outputId": "a9fdd999-15df-462f-c60a-b3b91c8236b1"
      },
      "source": [
        "import numpy as np\n",
        "batch_size=128\n",
        "EPOCHS=20\n",
        "callback_list=[Log2wandb_Callback(),lr_sched,model_cpt]\n",
        "model.fit(train_ds,epochs=EPOCHS, steps_per_epoch=np.ceil(86317/batch_size), \n",
        "          validation_data=test_ds, validation_steps=np.ceil(10778/batch_size),\n",
        "          callbacks=callback_list,\n",
        "          verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "epoch  1 : setting learning rate to  0.0001\n",
            "675/675 [==============================] - 421s 591ms/step - loss: 1.1687 - accuracy: 0.5818 - val_loss: 1.2422 - val_accuracy: 0.5973\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.59733, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 2/20\n",
            "epoch  2 : setting learning rate to  0.025075\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 1.0192 - accuracy: 0.6304 - val_loss: 1.0360 - val_accuracy: 0.6445\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.59733 to 0.64449, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 3/20\n",
            "epoch  3 : setting learning rate to  0.050050000000000004\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.9202 - accuracy: 0.6781 - val_loss: 1.1871 - val_accuracy: 0.5255\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.64449\n",
            "Epoch 4/20\n",
            "epoch  4 : setting learning rate to  0.07502500000000001\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.8795 - accuracy: 0.6980 - val_loss: 0.9929 - val_accuracy: 0.6594\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.64449 to 0.65938, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 5/20\n",
            "epoch  5 : setting learning rate to  0.1\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.8492 - accuracy: 0.7119 - val_loss: 1.0335 - val_accuracy: 0.6006\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.65938\n",
            "Epoch 6/20\n",
            "epoch  6 : setting learning rate to  0.08433333333333334\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.8006 - accuracy: 0.7320 - val_loss: 0.8505 - val_accuracy: 0.7095\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.65938 to 0.70947, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 7/20\n",
            "epoch  7 : setting learning rate to  0.06866666666666668\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.7614 - accuracy: 0.7463 - val_loss: 0.9625 - val_accuracy: 0.6625\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.70947\n",
            "Epoch 8/20\n",
            "epoch  8 : setting learning rate to  0.053000000000000005\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.7261 - accuracy: 0.7602 - val_loss: 0.7484 - val_accuracy: 0.7498\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.70947 to 0.74982, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 9/20\n",
            "epoch  9 : setting learning rate to  0.03733333333333334\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.6985 - accuracy: 0.7708 - val_loss: 0.8091 - val_accuracy: 0.7274\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.74982\n",
            "Epoch 10/20\n",
            "epoch  10 : setting learning rate to  0.02166666666666668\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.6676 - accuracy: 0.7786 - val_loss: 0.7200 - val_accuracy: 0.7549\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.74982 to 0.75487, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 11/20\n",
            "epoch  11 : setting learning rate to  0.006\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.6356 - accuracy: 0.7886 - val_loss: 0.6792 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.75487 to 0.77040, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 12/20\n",
            "epoch  12 : setting learning rate to  0.0055\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.6141 - accuracy: 0.7993 - val_loss: 0.6794 - val_accuracy: 0.7721\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.77040 to 0.77206, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 13/20\n",
            "epoch  13 : setting learning rate to  0.005\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.6115 - accuracy: 0.7988 - val_loss: 0.6709 - val_accuracy: 0.7729\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.77206 to 0.77289, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 14/20\n",
            "epoch  14 : setting learning rate to  0.0045000000000000005\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.5981 - accuracy: 0.8030 - val_loss: 0.6689 - val_accuracy: 0.7710\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.77289\n",
            "Epoch 15/20\n",
            "epoch  15 : setting learning rate to  0.004\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.5894 - accuracy: 0.8075 - val_loss: 0.6640 - val_accuracy: 0.7732\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.77289 to 0.77316, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 16/20\n",
            "epoch  16 : setting learning rate to  0.0035\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.5849 - accuracy: 0.8075 - val_loss: 0.6610 - val_accuracy: 0.7758\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.77316 to 0.77583, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 17/20\n",
            "epoch  17 : setting learning rate to  0.003\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.5765 - accuracy: 0.8100 - val_loss: 0.6665 - val_accuracy: 0.7747\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.77583\n",
            "Epoch 18/20\n",
            "epoch  18 : setting learning rate to  0.0025\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.5732 - accuracy: 0.8121 - val_loss: 0.6579 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.77583 to 0.77702, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 19/20\n",
            "epoch  19 : setting learning rate to  0.002\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.5718 - accuracy: 0.8122 - val_loss: 0.6596 - val_accuracy: 0.7763\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.77702\n",
            "Epoch 20/20\n",
            "epoch  20 : setting learning rate to  0.0014999999999999996\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.5637 - accuracy: 0.8165 - val_loss: 0.6558 - val_accuracy: 0.7760\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.77702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa3c81d6d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcOCYnOkbLL"
      },
      "source": [
        "def lr_schedule():\n",
        "    \n",
        "    def schedule(epoch):\n",
        "      \n",
        "      lr=np.interp([epoch],[20,25,EPOCHS], [0.001,0.006, 0.0001])[0]\n",
        "      print('epoch ', epoch+1, ': setting learning rate to ',lr)\n",
        "      return lr\n",
        "    \n",
        "    return LearningRateScheduler(schedule)\n",
        "\n",
        "lr_sched = lr_schedule()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjBcmd7GruFg",
        "outputId": "bc052e01-35e7-4b62-97ef-2bd0887ddd78"
      },
      "source": [
        "train_ds=ds.get_train_ds(training_files,batch_size=ds.batch_size,shuffle=True,distort=True,distort_fn=tfm.aug3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distorting...\n",
            "Finished 'get_tf_dataset_2' in 0.2412 secs\n",
            "Finished 'get_tf_dataset_in_batches' in 0.2415 secs\n",
            "Finished 'get_train_ds' in 0.2418 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-A9wVx_ArtN"
      },
      "source": [
        "cust = {'init_pytorch': init_pytorch}\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POj8Gf8cA4_Q"
      },
      "source": [
        "model=load_model('/gdrive/MyDrive/wandb-dw/best_model12.h5',cust)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5UwDgvvUIBM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f1cd0c-f9fb-48ff-9261-90f0b5788b9f"
      },
      "source": [
        "import numpy as np\n",
        "batch_size=128\n",
        "EPOCHS=40\n",
        "callback_list=[Log2wandb_Callback(),lr_sched,model_cpt]\n",
        "model.fit(train_ds,epochs=EPOCHS, steps_per_epoch=np.ceil(86317/batch_size), initial_epoch=20,\n",
        "          validation_data=test_ds, validation_steps=np.ceil(10778/batch_size),\n",
        "          callbacks=callback_list,\n",
        "          verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/40\n",
            "epoch  21 : setting learning rate to  0.001\n",
            "  6/675 [..............................] - ETA: 48s - loss: 0.5937 - accuracy: 0.8151WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0302s vs `on_train_batch_end` time: 0.0418s). Check your callbacks.\n",
            "675/675 [==============================] - 50s 73ms/step - loss: 0.5638 - accuracy: 0.8144 - val_loss: 0.6584 - val_accuracy: 0.7780\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.77702 to 0.77803, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 22/40\n",
            "epoch  22 : setting learning rate to  0.002\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5608 - accuracy: 0.8164 - val_loss: 0.6565 - val_accuracy: 0.7772\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.77803\n",
            "Epoch 23/40\n",
            "epoch  23 : setting learning rate to  0.003\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5612 - accuracy: 0.8152 - val_loss: 0.6555 - val_accuracy: 0.7775\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.77803\n",
            "Epoch 24/40\n",
            "epoch  24 : setting learning rate to  0.004\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5596 - accuracy: 0.8156 - val_loss: 0.6575 - val_accuracy: 0.7762\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.77803\n",
            "Epoch 25/40\n",
            "epoch  25 : setting learning rate to  0.005\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5605 - accuracy: 0.8144 - val_loss: 0.6622 - val_accuracy: 0.7688\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.77803\n",
            "Epoch 26/40\n",
            "epoch  26 : setting learning rate to  0.006\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5606 - accuracy: 0.8137 - val_loss: 0.6721 - val_accuracy: 0.7698\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.77803\n",
            "Epoch 27/40\n",
            "epoch  27 : setting learning rate to  0.005606666666666667\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5549 - accuracy: 0.8168 - val_loss: 0.6696 - val_accuracy: 0.7712\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.77803\n",
            "Epoch 28/40\n",
            "epoch  28 : setting learning rate to  0.005213333333333334\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5461 - accuracy: 0.8189 - val_loss: 0.6720 - val_accuracy: 0.7722\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.77803\n",
            "Epoch 29/40\n",
            "epoch  29 : setting learning rate to  0.00482\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5372 - accuracy: 0.8222 - val_loss: 0.6613 - val_accuracy: 0.7776\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.77803\n",
            "Epoch 30/40\n",
            "epoch  30 : setting learning rate to  0.004426666666666667\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5318 - accuracy: 0.8241 - val_loss: 0.6574 - val_accuracy: 0.7764\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.77803\n",
            "Epoch 31/40\n",
            "epoch  31 : setting learning rate to  0.004033333333333333\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5223 - accuracy: 0.8288 - val_loss: 0.6614 - val_accuracy: 0.7730\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.77803\n",
            "Epoch 32/40\n",
            "epoch  32 : setting learning rate to  0.00364\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5168 - accuracy: 0.8304 - val_loss: 0.6550 - val_accuracy: 0.7725\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.77803\n",
            "Epoch 33/40\n",
            "epoch  33 : setting learning rate to  0.003246666666666667\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5097 - accuracy: 0.8324 - val_loss: 0.6572 - val_accuracy: 0.7748\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.77803\n",
            "Epoch 34/40\n",
            "epoch  34 : setting learning rate to  0.0028533333333333336\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.5020 - accuracy: 0.8364 - val_loss: 0.6533 - val_accuracy: 0.7755\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.77803\n",
            "Epoch 35/40\n",
            "epoch  35 : setting learning rate to  0.0024600000000000004\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.4925 - accuracy: 0.8398 - val_loss: 0.6551 - val_accuracy: 0.7799\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.77803 to 0.77987, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n",
            "Epoch 36/40\n",
            "epoch  36 : setting learning rate to  0.002066666666666667\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.4854 - accuracy: 0.8431 - val_loss: 0.6534 - val_accuracy: 0.7758\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.77987\n",
            "Epoch 37/40\n",
            "epoch  37 : setting learning rate to  0.001673333333333334\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.4776 - accuracy: 0.8460 - val_loss: 0.6533 - val_accuracy: 0.7747\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.77987\n",
            "Epoch 38/40\n",
            "epoch  38 : setting learning rate to  0.0012799999999999999\n",
            "675/675 [==============================] - 49s 73ms/step - loss: 0.4715 - accuracy: 0.8486 - val_loss: 0.6483 - val_accuracy: 0.7767\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.77987\n",
            "Epoch 39/40\n",
            "epoch  39 : setting learning rate to  0.0008866666666666667\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.4648 - accuracy: 0.8533 - val_loss: 0.6495 - val_accuracy: 0.7743\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.77987\n",
            "Epoch 40/40\n",
            "epoch  40 : setting learning rate to  0.0004933333333333335\n",
            "675/675 [==============================] - 49s 72ms/step - loss: 0.4589 - accuracy: 0.8553 - val_loss: 0.6478 - val_accuracy: 0.7771\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.77987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa39e64f1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPNqt6Gk7oD1"
      },
      "source": [
        "model=load_model('/gdrive/MyDrive/wandb-dw/best_model12.h5',cust)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0UOlh1h8Ozt"
      },
      "source": [
        "opt=SGD(lr=0.0001,momentum=0.9,nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,metrics=['accuracy']\n",
        "              )"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecGf4bOl79j3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be86bbe-f22a-4fe3-fc10-1c3de623aafa"
      },
      "source": [
        "EPOCHS=41\n",
        "callback_list=[Log2wandb_Callback(),model_cpt]\n",
        "model.fit(train_ds,epochs=EPOCHS, steps_per_epoch=np.ceil(86317/batch_size), initial_epoch=40,\n",
        "          validation_data=test_ds, validation_steps=np.ceil(10778/batch_size),\n",
        "          callbacks=callback_list,\n",
        "          verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/41\n",
            "  6/675 [..............................] - ETA: 47s - loss: 0.4995 - accuracy: 0.8415WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0301s vs `on_train_batch_end` time: 0.0414s). Check your callbacks.\n",
            "675/675 [==============================] - 50s 73ms/step - loss: 0.4799 - accuracy: 0.8472 - val_loss: 0.6488 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.77987 to 0.77996, saving model to /gdrive/MyDrive/wandb-dw/best_model12.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa40000cf90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erylHhUun9v9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667,
          "referenced_widgets": [
            "1ece48fd90394113b804b0907f6ad64a",
            "c10d50541c764f13bb1198ece143454a",
            "43fccec0bc24409ca6030de32754c89d",
            "b2c98bc8761445d0b699b4449d24fc1a",
            "433d0f9aba0a472696b9d790e8a35e59",
            "a4756c0d7dc146b19c693170c70dce42",
            "55c50e2922404090a009ad6e6827bb9f",
            "9847692c052c4b889f51cf9b3a2ca768"
          ]
        },
        "outputId": "0aa6ce46-caf9-44f7-f104-603dbef1e822"
      },
      "source": [
        "run.finish()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 146<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ece48fd90394113b804b0907f6ad64a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.68MB of 0.68MB uploaded (0.04MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210421_151151-10pdt7my/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210421_151151-10pdt7my/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Epoch</td><td>40</td></tr><tr><td>Train Loss</td><td>0.47502</td></tr><tr><td>Train Acc</td><td>0.84785</td></tr><tr><td>Val Loss</td><td>0.64876</td></tr><tr><td>val_acc</td><td>0.77996</td></tr><tr><td>LR</td><td>0.0001</td></tr><tr><td>_runtime</td><td>2589</td></tr><tr><td>_timestamp</td><td>1619020500</td></tr><tr><td>_step</td><td>40</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Acc</td><td>▁▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>Val Loss</td><td>█▆▇▅▆▃▅▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▃▄▁▅▃▆▅▇▇▇██████████████████████████████</td></tr><tr><td>LR</td><td>▁▃▅▆█▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 25 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">draughtwatch_12</strong>: <a href=\"https://wandb.ai/ravindra/Wandb_Drought_Watch/runs/10pdt7my\" target=\"_blank\">https://wandb.ai/ravindra/Wandb_Drought_Watch/runs/10pdt7my</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}